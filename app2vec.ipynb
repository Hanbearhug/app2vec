{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open('text8') as f:\n",
    "    text = f.readline().split(' ')\n",
    "steps = int(len(text)/30)\n",
    "sentences = [text[30*index:30*(index+1)] for index in np.arange(steps)]\n",
    "for i in range(len(sentences)):\n",
    "    sentence = [word.lower() for word in sentences[i] if len(word)>0 and word.lower() not in ['a', 'an', 'the', 'is', 'am', 'was', 'are', 'and', 'or', 'of', 'for', 'he', 'she', 'i']]\n",
    "    sentences[i] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow.compat.v1 as tf\n",
    "class app2vec:\n",
    "    def __init__(self, sentences,  embedding_size, word2index=None, index2word=None, vocab_size=None,\n",
    "                 vocab=None, K=10, window_size=5, learning_rate=0.01, random_seed=79, distortion = 0.75,\n",
    "                 batch_size=64, is_weighted=False, sentences_gap_time=None, alpha=0.8, epislon=1e-3,\n",
    "                 use_log_distribution = True, min_word_count=5, epochs=10):\n",
    "        \"\"\"\n",
    "        app2vec的tensorflow实现\n",
    "        :param sentences: 训练语料（即app序列）\n",
    "        :param vocab_size: 字典大小\n",
    "        :param embedding_size: 嵌入矩阵的维度\n",
    "        :param word2index: 词到索引的转换字典\n",
    "        :param index2word: 索引到词的转换字典\n",
    "        :param vocab: 字典，如果use_log_distribution为真，则索引从小到大按照词频从大到小排列\n",
    "        :param K: 负采样的采样数量\n",
    "        :param window_size: 生成训练样本时的窗口大小（生成的训练样本长度为[batch_size, 2 * window_size]）\n",
    "        :param learning_rate: 反向传播学习率\n",
    "        :param random_seed: 随机种子\n",
    "        :param distortion: 用于对均匀分布进行扭曲，word2vec原论文中使用distortion=0.75来做扭曲使得词频大的样本\n",
    "        采样的频率不会过大，词频小的样本采样的频率不会过小\n",
    "        :param batch_size:训练时的batch_size大小\n",
    "        :param is_weighted:是否使用安装时间加权\n",
    "        :param sentences_gap_time:与sentences规格一样，每一个app的安装时间\n",
    "        :param alpha:\n",
    "        :param epislon:如果加权，每一个词的最小权重，防止loss爆炸，出现nan的情况\n",
    "        :param use_log_distribution:是否使用log分布抽样，如果是则vocab排序必须有序，如果否则默认\n",
    "        使用原word2vec中调整的均匀分布进行采样。\n",
    "        :param min_word_count: 进入词典的最小出现频次数，如果低于此数值则默认设置为unknown\n",
    "        :param epochs: 初始化训练次数\n",
    "        \"\"\"\n",
    "        if (is_weighted == True) and (sentences_gap_time is None):\n",
    "            raise Exception('加权条件下必须给出对应的gap_time值！')\n",
    " \n",
    "        self.random_seed = random_seed\n",
    "        if vocab_size and word2index and index2word and vocab:\n",
    "            self.vocab_size = vocab_size\n",
    "            self.word2index = word2index\n",
    "            self.index2word = index2word\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab, self.word2index, self.index2word, self.vocab_size = self._get_vocab_size_and_word_index(sentences, min_word_count)\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.window_size = window_size\n",
    "        self.get_vector = None\n",
    "        self.batch_size = batch_size\n",
    "        self.unigrams = list(self.vocab.values())\n",
    "\n",
    "        self.distortion = 0.75\n",
    "        self.K = K\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epislon = epislon\n",
    "        # self.word_vector 规格为[None, window_size, embedding_size]\n",
    "        self.is_weighted = is_weighted\n",
    "        self.sentences_gap_time = sentences_gap_time\n",
    "        self.alpha = alpha\n",
    "        self.use_log_distribution = use_log_distribution\n",
    "        self.distortion = distortion\n",
    " \n",
    "        self.sentences = self.preprocess(sentences)\n",
    "        self.word_weight=None\n",
    "        if self.is_weighted:\n",
    "            self.word_vector, self.word_weight, self.label = self.transform_sentences()\n",
    "        else:\n",
    "            self.word_vector, self.label = self.transform_sentences()\n",
    "        self.wordVectors = None\n",
    "        print(f'训练集大小为{self.word_vector.shape[0]}')\n",
    "        self._init_graph()\n",
    "        print(f'开始训练*******************************')\n",
    "        total_loss = self.fit(self.word_vector, self.label, self.word_weight, epochs=epochs)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def _get_vocab_size_and_word_index(self, sentences, min_word_count):\n",
    "        trans_sentences = []\n",
    "        index2word = dict()\n",
    "        vocab = dict()\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    vocab[word]+=1\n",
    "                except:\n",
    "                    vocab[word]=1\n",
    "        vocab_trans = dict()\n",
    "        for key in vocab.keys():\n",
    "            if vocab[key] < min_word_count:\n",
    "                try:\n",
    "                    vocab_trans['unknown'] += vocab[key]\n",
    "                except:\n",
    "                    vocab_trans['unknown'] = vocab[key]\n",
    "            else:\n",
    "                vocab_trans[key]=vocab[key]\n",
    "        vocab_trans['pad']=1\n",
    "        sorted_words = sorted(vocab_trans, key=lambda r: vocab[r], reverse=True)\n",
    "        word2index = dict(zip(sorted_words, range(len(sorted_words))))\n",
    "        index2word = dict(zip(range(len(sorted_words)), sorted_words))\n",
    "        vocab_size = len(sorted_words)\n",
    "        return vocab_trans, word2index, index2word, vocab_size\n",
    "\n",
    " \n",
    "    def _get_vector_count(self):\n",
    "        return self.word_vector.shape[0]\n",
    " \n",
    "    def _init_graph(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            tf.set_random_seed(self.random_seed)\n",
    " \n",
    "            self.weights = self._initialize_weights()\n",
    " \n",
    "            self.context = tf.placeholder(tf.int64, shape=[None, None], name='context')\n",
    "            self.output = tf.placeholder(tf.int64, shape=[None, 1], name='output')\n",
    " \n",
    "            self.context_v_vector = tf.nn.embedding_lookup(self.weights['embedding_v'], self.context,\n",
    "                                                           name='context_v_vector')  # [None, window_size, embedding_size]\n",
    "            self.output_u_vector = tf.nn.embedding_lookup(self.weights['embedding_u'], self.output,\n",
    "                                                          name='output_u_vector')\n",
    "            if self.is_weighted:\n",
    "                self.context_weight = tf.placeholder(tf.float32, shape=[None, None, 1], name='context_weight')\n",
    "                self.context_weight_norm = tf.div(self.context_weight,\n",
    "                                                  tf.reduce_sum(self.context_weight, keepdims=True, axis=1),\n",
    "                                                  name='context_weight_norm')\n",
    " \n",
    "                self.weighted_context_v_vector = tf.multiply(self.context_v_vector, self.context_weight_norm,\n",
    "                                                             name='weighted_context_v_vector')\n",
    "                self.context_v_vector_average = tf.reduce_mean(self.weighted_context_v_vector, axis=1,\n",
    "                                                               name='context_v_vector_average')\n",
    " \n",
    "            else:\n",
    "                self.context_v_vector_average = tf.reduce_mean(self.context_v_vector, axis=1,\n",
    "                                                               name='context_v_vector_average')  # [None, embedding_size]\n",
    "            # self.log_likelyhood_denominator = tf.reduce_sum(tf.exp(tf.matmul(self.context_v_vector_average, tf.transpose(self.u, [1, 0]))), name='log_likelyhood_denominator') # [None]\n",
    "            # self.log_likelyhood_numerator = tf.diag_part(tf.matmul(self.output_u_vector, tf.transpose(self.context_v_vector_average, [1,0])), name='log_likelyhood_numerator') # [None]\n",
    "            # self.log_likelyhood = tf.reduce_sum(tf.log(self.log_likelyhood_denominator) - tf.log(self.log_likelyhood_denominator), name='log_likelyhood')\n",
    "            nce_biases = tf.Variable(tf.zeros([len(self)]))\n",
    "            if not self.use_log_distribution:\n",
    "                sample_values = candidate_sampling_ops.fixed_unigram_candidate_sampler(\n",
    "                    true_classes=self.output,\n",
    "                    num_true=1,\n",
    "                    num_sampled=self.K,\n",
    "                    unique=True,\n",
    "                    range_max=len(self),\n",
    "                    seed=self.random_seed,\n",
    "                    distortion=self.distortion,\n",
    "                    unigrams=self.unigrams\n",
    "                )\n",
    "            else:\n",
    "                sample_values = None\n",
    " \n",
    "            self.loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(\n",
    "                    weights=self.weights['embedding_u'],\n",
    "                    biases=nce_biases,\n",
    "                    labels=self.output,\n",
    "                    inputs=self.context_v_vector_average,\n",
    "                    num_sampled=self.K,\n",
    "                    num_classes=len(self),\n",
    "                    sampled_values=sample_values\n",
    "                )\n",
    "            )\n",
    " \n",
    "            self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    " \n",
    "            init = tf.global_variables_initializer()\n",
    "            self.sess = self._init_session()\n",
    "            self.sess.run(init)\n",
    " \n",
    "    def _init_session(self):\n",
    "        config = tf.ConfigProto(device_count={\"gpu\": 0})\n",
    "        config.gpu_options.allow_growth = True\n",
    "        return tf.Session(config=config)\n",
    " \n",
    "    def get_batch(self, word_vector, label, word_weight=None):\n",
    "        steps = int(word_vector.shape[0] / self.batch_size) + 1\n",
    "        for i in range(steps):\n",
    "            try:\n",
    "                word_batch = word_vector[i * self.batch_size:(i + 1) * self.batch_size, :]\n",
    "                label_batch = label[i * self.batch_size:(i + 1) * self.batch_size, :]\n",
    "                if self.is_weighted:\n",
    "                    weight_batch = word_weight[i * self.batch_size:(i + 1) * self.batch_size, :]\n",
    " \n",
    "            except:\n",
    "                word_batch = word_vector[i * self.batch_size:, :]\n",
    "                label_batch = label[i * self.batch_size:, :]\n",
    "                if self.is_weighted:\n",
    "                    weight_batch = word_weight[i * self.batch_size:, :]\n",
    " \n",
    "            if self.is_weighted:\n",
    "                yield word_batch, weight_batch, label_batch\n",
    "            else:\n",
    "                yield word_batch, label_batch\n",
    " \n",
    "    def fit_on_batch(self, word_batch, label_batch, weight_batch=None):\n",
    "        if self.is_weighted:\n",
    "            feed_dict = {\n",
    "                self.context: word_batch,\n",
    "                self.output: label_batch,\n",
    "                self.context_weight: weight_batch\n",
    "            }\n",
    "        else:\n",
    "            feed_dict = {\n",
    "                self.context: word_batch,\n",
    "                self.output: label_batch\n",
    "            }\n",
    " \n",
    "        loss, opt = self.sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "        return loss\n",
    " \n",
    "    def shuffle_word_label(self, word_vector, label, word_weight=None):\n",
    "        index = np.random.permutation(range(word_vector.shape[0]))\n",
    "        word_vector = word_vector[index, :]\n",
    "        label = label[index]\n",
    "        if self.is_weighted:\n",
    "            word_weight = word_weight[index, :]\n",
    "            return word_vector, word_weight, label\n",
    "        else:\n",
    "            return word_vector, label\n",
    " \n",
    "    def fit(self, word_vector, label, word_weight=None, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            steps = int(word_vector.shape[0] / self.batch_size) + 1\n",
    "            total_loss = []\n",
    "            if self.is_weighted:\n",
    "                word_vector, word_weight, label = self.shuffle_word_label(word_vector, label, word_weight)\n",
    " \n",
    "                for word_batch, weight_batch, label_batch in tqdm(\n",
    "                        self.get_batch(word_vector, label, word_weight), total=steps, postfix=f'epoch: {epoch}',\n",
    "                        leave=False):\n",
    "                    if len(word_batch) == 0:\n",
    "                        break\n",
    "                    loss = self.fit_on_batch(word_batch, label_batch, weight_batch)\n",
    "                    total_loss.append(loss)\n",
    "            else:\n",
    "                word_vector, label = self.shuffle_word_label(word_vector, label)\n",
    " \n",
    "                for word_batch, label_batch in tqdm(self.get_batch(word_vector, label), total=steps,\n",
    "                                                             postfix=f'epoch: {epoch}', leave=False):\n",
    "                    loss = self.fit_on_batch(word_batch, label_batch)\n",
    "                    total_loss.append(loss)\n",
    "            print(f'epoch: {epoch} loss:{np.mean(total_loss)}')\n",
    "        self.wordVectors = self.sess.run(self.weights['embedding_u'])\n",
    "        self.word_norm = np.sqrt(np.square(self.wordVectors).sum(axis=1))\n",
    "        return total_loss\n",
    " \n",
    "    def preprocess(self, sentences):\n",
    "        post_sentences = []\n",
    "        for sentence in sentences:\n",
    "            if len(sentence) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_sentence = [word if (word in self.word2index.keys()) else 'unknown' for word in sentence]\n",
    "                post_sentences.append(new_sentence)\n",
    "        return post_sentences\n",
    " \n",
    "    def transform_sentences(self):\n",
    "        word_vector = []\n",
    "        word_weight = []\n",
    "        labels = []\n",
    "        if self.is_weighted:\n",
    "            for sentence, gap_time in tqdm(zip(self.sentences, self.sentences_gap_time),\n",
    "                                                    total=len(self.sentences)):\n",
    "                if isinstance(sentence, list):\n",
    "                    sentence = ['pad'] * self.window_size + sentence + ['pad'] * self.window_size\n",
    "                    if self.is_weighted:\n",
    "                        gap_time = [0] * self.window_size + gap_time + [0] * self.window_size\n",
    "                    for word_index in range(self.window_size, len(sentence) - self.window_size):\n",
    "                        window = [sentence[word_index + i] for i in range(-self.window_size, self.window_size + 1) if\n",
    "                                  i != 0]\n",
    "                        vector = [self.word2index[word] for word in window]\n",
    "                        \n",
    "                        vector_window = [gap_time[word_index + i] for i in\n",
    "                                         range(-self.window_size, self.window_size + 1) if i != 0]\n",
    "                        label_time = float(gap_time[word_index])\n",
    "                        vector_weights = [self.epislon if vector_gap == 0 else max(self.epislon, self.alpha ** (\n",
    "                                    abs(float(vector_gap) - label_time) / 8640000)) for vector_gap in vector_window]\n",
    "     \n",
    "                        label = self.word2index[sentence[word_index]]\n",
    "                        if len(vector_weights) == len(vector):\n",
    "                            word_weight.append(vector_weights)\n",
    "                            word_vector.append(vector)\n",
    "                        else:\n",
    "                            print('权重和向量长度不相等！')\n",
    "                        labels.append(label)\n",
    "        \n",
    "            return np.array(word_vector), np.expand_dims(np.array(word_weight), axis=2), np.array(labels).reshape(\n",
    "                (-1, 1))\n",
    "        else:\n",
    "            for sentence in tqdm(self.sentences, total=len(self.sentences)):\n",
    "                if isinstance(sentence, list):\n",
    "                    sentence = ['pad'] * self.window_size + sentence + ['pad'] * self.window_size\n",
    "                    for word_index in range(self.window_size, len(sentence) - self.window_size):\n",
    "                        window = [sentence[word_index + i] for i in range(-self.window_size, self.window_size + 1) if\n",
    "                                  i != 0]\n",
    "                        vector = [self.word2index[word] for word in window]\n",
    "                        label = self.word2index[sentence[word_index]]\n",
    "                        word_vector.append(vector)\n",
    "                        labels.append(label)\n",
    "            return np.array(word_vector), np.array(labels).reshape((-1, 1))\n",
    " \n",
    "    def _initialize_weights(self):\n",
    "        weights = dict()\n",
    " \n",
    "        # embeddings\n",
    "        weights['embedding_u'] = tf.Variable(\n",
    "            tf.random_normal([self.vocab_size, self.embedding_size], 0.0, 0.01),\n",
    "            name='embedding_u'\n",
    "        )\n",
    " \n",
    "        weights['embedding_v'] = tf.Variable(\n",
    "            tf.random_normal([self.vocab_size, self.embedding_size], 0.0, 0.01),\n",
    "            name='embedding_v'\n",
    "        )\n",
    "        return weights\n",
    " \n",
    "    def get_weight(self, app):\n",
    "        if isinstance(app, str):\n",
    "            app = np.array([self.word2index[app]]).reshape((-1, 1))\n",
    "        else:\n",
    "            app = np.array([app]).reshape((-1, 1))\n",
    "        app_weights = self.sess.run(self.output_u_vector, feed_dict={self.output: app})\n",
    "        return app_weights\n",
    " \n",
    "    def get_most_similar(self, word=None, k=10):\n",
    "        word_index = self.word2index[word]\n",
    "        word_vector = self.wordVectors[word_index, :]\n",
    "        app_norm = np.sqrt(np.square(word_vector).sum())\n",
    " \n",
    "        cos_similarity = np.dot(self.wordVectors, word_vector) / (self.word_norm * app_norm)\n",
    "        most_k = np.argsort(cos_similarity)[-k:]\n",
    "        most_similar_word = [self.index2word[i] for i in most_k]\n",
    "        return most_similar_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 50000/50000 [00:03<00:00, 12828.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小为1222362\n",
      "开始训练*******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 18/19100 [00:00<01:47, 176.94it/s, epoch: 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss:19.457204818725586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 21/19100 [00:00<01:33, 204.42it/s, epoch: 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss:11.265423774719238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 21/19100 [00:00<01:33, 203.55it/s, epoch: 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 loss:10.57028865814209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 18/19100 [00:00<01:46, 178.70it/s, epoch: 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 loss:10.206185340881348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 20/19100 [00:00<01:38, 192.82it/s, epoch: 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 loss:9.980178833007812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 18/19100 [00:00<01:51, 171.89it/s, epoch: 6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 loss:9.872269630432129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 18/19100 [00:00<01:49, 173.53it/s, epoch: 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 loss:9.665048599243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 19/19100 [00:00<01:43, 184.96it/s, epoch: 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 loss:9.649993896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 18/19100 [00:00<01:51, 171.88it/s, epoch: 9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 loss:9.532127380371094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 loss:9.397991180419922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "App2Vec = app2vec(sentences[:50000], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['again',\n",
       " 'last',\n",
       " 'eighth',\n",
       " 'third',\n",
       " 'beating',\n",
       " 'second',\n",
       " 'ivo',\n",
       " 'subsequently',\n",
       " 'fourth',\n",
       " 'first']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "App2Vec.get_most_similar('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wells',\n",
       " 'rainbow',\n",
       " 'disaster',\n",
       " 'green',\n",
       " 'pink',\n",
       " 'brazilian',\n",
       " 'black',\n",
       " 'white',\n",
       " 'yellow',\n",
       " 'red']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "App2Vec.get_most_similar('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_gap_time = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    gap_time = [1606352522]*len(sentence)\n",
    "    sentences_gap_time.append(gap_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:11<00:00, 4327.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小为1222362\n",
      "WARNING:tensorflow:From C:\\Users\\hugbear\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-2-157cd980c717>:124: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练*******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss:20.632997512817383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss:11.667088508605957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 loss:11.358113288879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 loss:11.186979293823242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 loss:10.996045112609863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 loss:10.876816749572754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 loss:10.586947441101074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 loss:10.557825088500977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/19100 [00:00<?, ?it/s, epoch: 9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 loss:10.389039039611816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 loss:10.218778610229492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "App2Vec_time = app2vec(sentences[:50000], 30, sentences_gap_time=sentences_gap_time[:50000], is_weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patented',\n",
       " 'time',\n",
       " 'introduced',\n",
       " 'title',\n",
       " 'last',\n",
       " 'fourth',\n",
       " 'second',\n",
       " 'third',\n",
       " 'originally',\n",
       " 'first']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "App2Vec_time.get_most_similar('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['player',\n",
       " 'car',\n",
       " 'african',\n",
       " 'indian',\n",
       " 'rye',\n",
       " 'bradford',\n",
       " 'cross',\n",
       " 'white',\n",
       " 'black',\n",
       " 'red']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "App2Vec_time.get_most_similar('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VMXXwPHvpGwaNXSSUKR3hJCE3jsi0kQQERBsqEgREYFXKSrFnwIK0qVI7z1EivQqIr2FkBBAICCmt3n/2LASkghskt1NOJ/nycPuvbN3zg2Bk7nTlNYaIYQQwhx21g5ACCFE1uVg7QCEEEbKU3mRA2erBhFOtA7RwVaNQWQpkkSEsBU5cOY1IqwawxLcrFq/yHLkcZYQQgizSRIRQghhNkkiQgghzCZJRIjsag61GcfP1g5DZG+SRIQQQphNRmcJYcs24ckxfsGRw8RRAwfOUJBl3GAwmvyUZAAAV/kCcAaiqcQgOnI52XXO4cIaxhJPBcCe/EzmXfwtfj8i25GWiBC2LpESvMBshtCUBEpzmw58SgcK8CXX+JCqXOJ9OjKSlhRhEmf5NMU11vMROdjHSNrQhi7cZiTncLHC3YhsRloiQtg6O67xKucAcOA8OdiLI+DJOW7jyQ1ysZHvSaAkoAHHFNeIoSHRtOBL3gFA48wpPCjPJcvdiMiOJIkIYftiH3mdiH3SezsSAQd+Zyiu7ONj+rIJT46yKpVrKCrTL8VjLiHSSZJIJrCJ5SvSIstaZD+J5MKJmwCc4dVUyzixiwv0Jo7PcQR+oTLdOWXBKEU2pWx5Fd/8+fPrEiVKWDuMZxadEI2dq212NyVGJuJsb5v57XmX2s9NbHQsV89epeyLZQEIvhhMrry5yJ0/t+mcR2kPQi6G4ODogFtuN+7fvk/5muUJ/zucO6F3KFGhBIkJidy4eoOIfyJAg8HZQIkKJVLEID8fWd+xY8fuaK0LWKo+m26JlChRgqNHj1o7jGd2IfACOfLnsHYYqQq/E07ZkmWtHYZIhS383MjPR9anlAqyZH22+euyEEKILEGSiBBCCLPZ9OOs59XdO3fp1aUXsXGxjJkwhr9u/cWkcZMoUKgAKzettHZ4Qggbcu36NaJjo/894ISTKq/KZHrFSYN0MiSJKKXmAu2Av7TWlVM5r4DvgTZAJPCm1vp4RtSdHe3dtZdSZUvx/U/fA9DjlR6M/3Y8dRvUtXJkQghbEx0bnbwvzZlEi+xLk7T3TEa1ROYD04AFaZxvDZRJ+vIFpif9+VxZ8csKfpr6EyioUKkCw0YOY9D7gwi7E4Z7fnf+9+P/uHfvHmNHjSU6KprmdZvTul1rDh88zLWB12jRpgWfffEZ40eP58CeA8TGxtKrXy969ukJwPTvp7Nh9QYiIiKo16QefQb0SRFDZFhkht+Xs8GZYh7FMvy6zxtngzPhd8KtHoMQzyJDkojW+jelVIn/KPIysEAbxxMfVErlUUoV0VrfyIj6s4LzZ88zZdIU1m1fh3s+d+6F3WPgOwPp3K0zXXt0ZenCpYz8ZCRzl8xlyIghnDx+knGTxwGwf89+Ro4dSbUa1Vg0bxE5c+Vk8+7NxMTE0KFFBxo2aUjg5UACLweyadcmLgVd4vNBn3P+wnlq+NVIHogmw0cAWfs/vuxCErHIiizVJ+IBPDrBLSTpWIokopTqD/QHKFYs+/yj2rd7H207tMU9nzsAed3zcuzwMWYvng1Ap26dGDty7BOvs3vHbs6eOsumdZsA+OfBPwReDmT3jt3s3rGbFvVaEBsbS3RMNNeuXEuZRIRIRYrn6jZMWr62xVJJRKVyLNVZjlrrmcBMAG9vb9udCfmMtNaoVL8N/zJ2HT3pQjB24lgaNWuU7PCuX3cxYNAAevbpyeVrl3Fzl62yxdNL8VzdhknL9ykYV39ewCiamI4toirX6cIwRmZkVZYa4hsCeD3y3hMItVDdNqFeo3psWLOBsLthANwLu4e3rzfrVq4DYPXy1fjU9nnidRo2bciCOQuIi4sD4PLFy0RGRNKoaSOWLVxGRLixP+2vG38Rdicsk+5GCJHlvM7JjE4gYLmWyHpggFJqKcYO9b+fp/4QgHIVyvHhkA/p3KYzdvZ2VK5amTETxjDo/UHMmDLD1LH+JN17dSf4WjCt6rdCa417fnfm/jKXhk0bcvH8Rdo3a09MXAw5cuVgzNQxuOd3f6Y4hwwYQv8B/SlbXmYtC5EtbKAYJ5iFK2uJxo8R9GIig4mnKAkUJwEPcjGLj5kLwCQGEklH7AjFjjCcOMlgZqR1+QxZO0sptQRoBOQHbgGjSVqOWms9I2mI7zSgFcYhvr211k9cz8Tb21s/67IntvBsN/RWKGUrWe8/4f96nBVxN4IXir2A1ho7u4xpiMpSGVmfLSy58rTk5y25x//uPLw8TlKWfhxjAZXpx2l+pDSDiCQXN3nHlESiaUBvuhCEGwHs4T2qs42KXGESr9OeCOxZwzbcWJRqElmCmz6nL2bU6KzXnnBeA+9nRF1PYgvPdmNCYqxaf2pCQ0L5oN8HVKtYjUunL1GpSiXOnTlHdFQ0bV9uy5ARQwDo3KazaSRYmSJl6PtuXwK2BuDs7My8pfMoUNBi67oJK5szfQ4L5iygSrUqTJszLcOvP3n8ZNxyuPHOh+9k+LUFoMnHKeZRnrfoygXmUDvZeRd+xZNYPInlV+5ynAL8hQ8ubOMFjL+Jb2b7k6qRZU+eI1evXKVlu5b47/Vn1LhRbNm9hYADARzcd5Azp86kKB8ZEUmNWjUI2B+AX10/Fs9fbIWohbX8PPtnFq5cmCkJRFiA4gF2hHKDWmmcf3SfmgTisSf1QVD/SZY9eY4U9ShK5arGBQU2rNnA4vmLSYhP4NbNW1w8d5GKlSsmK28wGGjeqjkAVapXYc/OPRaPWVjHsIHDuHb1Gr279aZ9p/YEBQZx7vQ54hPiGTx8MC3btmTZ4mVs27iNhIQEzp89z9sD3iY2LpZVS1dhMBhYuHIhed3zsnj+YhbPW0xsXCwlXyjJlJlTcHFNvjPv1StXGTF4BHfv3sXFxYWJUydSumxpK919thFHZ3qzgiVMIwIXbj3xEwU4zFUmEMQ0IrAnhqY48Mt/fURaIs8RFxfjP9xrV6/x05SfWLZ+GQEHAmjasinRMSn7kRwcHUzDju3t7YmPj7dovMJ6vvnuGwoVKcSKTSuIjIykboO6bN69mRUbVzDm8zFERhhXPjh/5jw/zPmBTTs38c2Yb3BxccF/rz81fWqycolxnbfWL7Vm8+7NBOwPoHTZ0ixZsCRFfZ989AljJo5h629bGTl2JMMHDbfo/WZb5YmiDW9wj/7EkvOJ5XvyB8748zPbWc0cHDiJAw/+6yPSEskETo5OVh3LHhkWmWIWTuS9SBKjEnFydOLvu3/j4uZCrty5uP3XbXZu30nt+rVTv5h47v224ze2b97OjKnGvtWYmBiuh1wHoE6DOuTImYMcOXOQM1dOmrc2tlwrVKpgekR6/ux5JoyZwIO/HxAREUHDpg2TXT8iPIJjh47xdq+3TcdiY2IR6dCWENomzRGpyQNq0ibpjD8AQ5mcrPyj80naMp2KTOYizixlDfnTHpkFkkQyRdFCRa0+euTxwQUGDBiUAc+inngW9aRy1co09mlMsRLFqOWX+iNTIcA4UXbmopmULpP88dLxo8cxGAym93Z2djg5OQGg7BQJ8QkAfPzux8z5ZQ6VqlRi2eJlHNhzINl1EhMTyZU7F9v3PbEPV1jCWiaykjKAM24sp8d/b6Oc7R9nRUZE0rNzT5rVaUYT3yasW7UO38q+TBo3iZb1W9LUrymXLlwCjBMA+7zWh2a1m9GuSTvTb1JN/Zry9/2/0VpTqXglVvyyAoAP+n3Abzt/s9q9PQuv4l7sOLTD9P67Gd+x++huFq5cyOzFs3m1h3Fr7pWbV1KtRjUALt64aCrfrkM7vpvxnWWDFjahYdOGzJsxj4fTAU798Wxbs4f/E06hwoWIi4tjzfI1Kc7nzJUTr+JebFizATAmrdN/nk5/4MI8n/E+o2jBKBowmCeOqsj2SWRnwE4KFylMwP4AdhzaQeNmjQFwz+fOtj3b6Nm3JzOmGFtrk8dPpnLVygQcCODT0Z/y0dsfAeDt582Rg0c4f/Y8xUsU5/CBwwAcP3KcmrVqWufGhLCQgZ8MJC4+jma1jb+ITRg74Zk+P/TzobRr0o7XXn4tRWvmoWmzp7F0wVKa1WlGY5/G+G/yz4jQhQVkyGTDzGLOZMPHJ95cvniZHh178NIrL9GsVTN86/jiW9mXtf5rKVK0CMePHOebMd+wbP0yWtRrwayFsyhesrix/gre7Di4g4CtAZw9fRYPLw+cnZ1ZNG8RsxbNol+PfmzcuTFFDNaeDGXpiWPWvl+RfjLZMOtKdbLhx7TO9IozcrKhLStVphRbdm9hh/8Ovvq/r2jYxNip9/DZrb29venZbWoJVSmFb11f5s+aj6eXJ8NGDWPLhi1sWrsJnzpPXutKCCEyU4p9aKKxe7hhVKYKN05IzPZJ5OaNm+TJm4dO3TrhlsON5YuXp1nWr44fq5ev5uNhH7N/z37c87mTM1dOcubKSdjdMOLi4ihesjg+tX2YMXUG4yaNs+CdCCFESimWxY8hRp/TF1MvnfFsKokoT+VFDkxbq1VyqcSFwAvPdI3AkEBcI11N7w/vO8yPk37Ezs4OBwcHBo0cxB+D/iAwJJCo2Khknx00fBCD3htEs9rNcHZxTtaR/KL3iyQmJALgU8eHr/7vK5sd1WTpHfJkNzwhnl821Seiyqsyj+4NXMW/yvWtW7c+0zUuB13GLd/TteQiwiIoVazUswX5FOSZrchqpE8k+1BKHdNae1uqPptqiQghrMMW9nd/WtLytS2SRIQQst2sMFu2nycihBAi82T7JPLTlJ9YOGehtcMQQohsKds9znJydCLirqlvnth/YrFPsE927KHIe5GEu6bvOXDorVBi4pJvQuXk6JSua2YEZ4OzPKIQQmQ6m08iK35ZwU9TfwJlXBl02MhhDHp/EGF3wkz7knt4eRByLSTV4+453XHL4Uap4ilHYYW7ZcwoD1sc1ZJVOkmFEFmbTT/Oio6MZsqkKSzfuJyA/QF8+c2XjBgygs7dOhNwIICOXTsy8pORAGkeF0IIkXlsOomE/x1O2w5tcc/nDkBe97wcO3yMV7q+AkCnbp1MiyGmdVwIIUTmsekkAqCesOXvw533nva4EEKIjGPTfSI5cudgw5oN9Hu/H+753LkXdg9vX2/WrVxH59c6s3r5anxqGxdBTOt4drV/z34cDY7U8rXNpVeEEMldu36N6NiU21BnOCecVHlV5pk/F060DtHBz/qxDEkiSqlWwPeAPTBba/31Y+cbAeuAwKRDq7XWXz7pus6uzvR5uw+d23TGzt6OylUrM2bCGAa9P4gZU2aYOtCBNI9ndddvXCc6LuUP3qaNm3BxdcG9iHuqn4sMi8yUeGTUlxDmiY6NtswgHGcSH10+6qmZufJvupOIUsoe+AFoDoQAR5RS67XWZx4rukdr3e5Zr9+1R1e69uia7NiKjStSlPMq7pXq8cGfDX7WKtMtMiKSt3u9zY3QGyQmJNKpWyd+P/o7sxfPZtumbbzX+z3OhpwlMTGRxj6NOXDyAFevXGXE4BHcvXsXFxcXJk6dSOmypbl56ybfff0dN6/fNN7PF4NRDoq1q9ei7BVbNm/hrY/fomK1isliiIqKwjXCNbXwnsjJ0QnPop6pnpNRX0KIR2VES8QHuKS1vgKglFoKvAw8nkSeGw93U1y40jjJ8cHfD1g41/j60P5DlKtQjj+O/0F8fDwv1nwRgE8++oSv//c1L5R+geNHjjN80HBWbFzBlK+n0L1fd170fZEbITcY0H0A3y7+lravt8XZ1Zkub3RJPQjFUy9E+bjU5tQIIURqMiKJeACPPkcLAXxTKVdbKfUHEAoM0VqnvonybHrwD68D3C18NwPCs7zyFcsz5vMxjBs1zrSbYokXSnDx/EVOHDtB/wH9ObjvIAkJCfjU8SEiPIJjh47xdq+3TdeIjYkF4OjBo1y7es10PCI8gqjIqBR1CiGENWREEkltGNTj68sfB4prrcOVUm2AtUDqHT9vsRhYDJDPP9/1DIjP4lLbTdG3ti87tu/AwdGB+o3rM/CdgSQmJDJy3EgSExPJlTsX2/dtT3EtnaiZt2Eezi7/rlwaFBxkydsRQog0ZcQQ3xDA65H3nhhbGyZa6wda6/Ck15sBR6VU/gyo2ybdvHETF1cXOnXrxDsfvsOff/yJb11fZv84m5q1apIvfz7uhd3j0sVLlKtQjpy5cuJV3IsNazYAxm16T/9pbKjVqlOL5fP+3Y3x/KnzALi4uRAVYX6LZPH8xURH/dthX7d6XbOvJYR4fmVES+QIUEYpVRK4DnQDuj9aQClVGLiltdZKKR+MySvls6pwoh8dIZDokpipHbmZtS/BudPnGDtyLMpO4ejgyFf/+4qyFcpy5687+NX1A6Bi5Yr8desv03yWabOnMfzj4Xw/8Xvi4+J5udPLVKpSiQ+Hf8jUCVN5temrJMQnUMOvBj0G9MCvgR9jh47l4K6D9P6gNzeDbvJSj5eeKr6EhASW/LyEti+3TdbCEUJY3vcTv2flkpUU9SxKvnz5qPpiVQK2BjBy7Eiq1ahG2N0wWjdszaFTh0hISGD86PEc2HOA2NhYevXrRc8+PQGY/v10NqzeAP9QlokMZiiT2YQnx1iMI4eJwxs7btKd3rxAho01TncS0VrHK6UGANswDvGdq7U+rZR6J+n8DKAz8K5SKh6IArrpVLZUfHyMsre3d5bcwaxRs0Y0atYoxfHAO4Gm1xOmTEh2rliJYixeszjFZ/LkzcPXP/07YvrnWT+zce1GuvbpSrX61Qi8FIhXCS+mjpzKmctn8Knjw9IFS0mMSqRJ4yZ8OPRDwNjSeL336xzcc5B6jepx+6/b9O/Znzx58zBz4UwApv1vGnt27sExwZElK5ZQoGCBjPh2CCHScPL3k6xftR7/vf7Ex8fTqn4rqr5YNc3ySxYsIWeunGzevZmYmBg6tOhAwyYNCbwcSODlQDbt2oSnl+cFoqjKXHwpxHUSKUkJ3uM1hjKeGWyiDR+wOqPuIUNmrGutN2uty2qtS2mtxyUdm5GUQNBaT9NaV9JaV9Na+2mt92dEvc+jF71f5Mwp48C3S+cuER0ZzZwJc7h78y4ntp1gyqgp1KtVD0OMgeWzlvPpe58CEB0Vzf5t+4n/Jx7/lf64GdyYuXCmKYFER0VTpVoVlq1fRrUa1Vg8P2VCE0JkrEP7D9GqXStcXF3ImSsnzds0/8/yu3fsZuWSlTSv25x2TdpxL+wegZcD2b1jN7t37KZFvRYQTlkSKM0/lATAjmu8hvH5uBMniUnW/ZBuNj1jXaRUsXJFLl+8TGREJA6ODpQuW5rKlStzZM8Rug7sysEdBwm7FcaE+RP4ff/vzP1+LscPHsfOzo7vF3yPe353oqOiaVihIX/f/5s8efMA4OjoSIPGDQAoV6EcF05esOZtCvHcSG2JJnsHexITEwGIjn7kyZOGsRPHpnjSsevXXQwYNICefXri4eVxgY9pDcAmPIHYR4omojP2/32bXztLJOfg6EChQoXw3+JPxcoVqVy1MufOnCMuPo6ChQoSFhrGsb3HGPz6YGZNmsWDew+4duUaBicDK+avoFuzbrz50pskxCdwPejfwW/2DvamH2Z7e3vi4+OtdYtCPDf86vqxdeNWoqKiCP8nnO1bjCM0vYp5cfLESQA2rd1kKt+waUMWzFlAXFwcgOkXykZNG7Fs4TIiwpPmeG2nML+RzxL3IEkkC6pYuSIrl66kcvXKVK5WmR3bd2AwGKhQsQJ3bt+h/RvtmbRwEsUqFeOLaV/QoXsHEmITOLTnEPPWz2NpwFKcXJ14cP+BtW9FiOdalepVeKnjS7So24J+r/fDt45xit07H77DwjkLad+sPWF3w0zlu/fqTpnyZWhVvxVNfJswbOAw4uPjadi0IR26dKB9s/bGjvWDzOQ+FtnoSB5npZOzwTlTR5BFhkWmmHXzQokXWLFsBSU9SuKknHDUjsQSi7O9M61easWC7xewZeMWmjZtSsWKFQm7EwYacuXOhYurC4EXA4mLjmPKpCmsXrXa1C8ihLC8j4Z+xEdDPwJg8vjJAJQuW5qAAwGmMsNGDQPAzs6O4aOHM3z08BTXeeu9t3jrvbcePs5qbzrRliam14OZkdHxq1QGSdkMb29vffToUWuHYVUXAi+kWLTtctDlFEuafPbeZ1w6e4k6jetQsGhB1v6yFgBXN1fGTB1DoSKFGNxnMH/d/IvipYpz/+59+g/uj3cd7xR1RtyNSHUnSDCunZUVR8wJYW2p/Vt+3OTxk3HL4cY7H75jdj0eXh4nTX0iz2IJbvqcvvisH5OWSDYx/sfxyd53f6t7ijJTF0+1VDhCCDNYY8HY9JIkYkVPs79AYEhgitV4g0ODcYlyybS4ou4ZZ8L/12q+QggBkkSs6mn2F3CNdMXNPfmjK5dIF1zzmrfM+1PRxhWAZTVfIcSTSBIRQggLyOxBOCbR2Jm1wVS4eUuhSBKxcc6OzkSEJW8RRN2PytTB2VH3o4hwiyDyXiThbsl/6DNrvTEhsjuL7QgaQ4w5HeTmkiRi4zyKeKQ45uTgRExcTKbV6VTc2BcS7iojsYQQ/02SiI0JDgqmV9de7Di0I80y/9XZPXHsRHzr+pqWMBFCiMwkSSSLCwkNMbVKEhMT6dizI2CcS5JekfciTa+dDc6Wa44LIbIMSSI2KD4+no/e/ojTJ09TsnRJpvw0haOHjzLm8zEkxCdQrUY1vvrfVzg5OdG+RXteef0VDuw7wKs9XmX/nv3Ub1yfZq2a0a5xO9p1aMdvu34jPi6eCVMmUOKFEtwLu8dngz/j7/t/U7FKRQ7sOcDi1YtNizGaKEyjxyzSISiEyHJk7SwbdPniZV7v/ToBBwLImTMnP037iY/f/Zjp86bz68FfiY+PZ8HsBabyBicDc5fMpWW7limulSdvHn5Z8wudX+vMgjnGz8ycOpNafrX4Zc0vNGnWhJuhNy12b0KI7EWSiA0q6lmUWn61AOj4akf27t5LseLFKFXGuBRJl+5dOLT/kKl8izYt0rxWk5bGZXMqVKpA6HXjrsW/H/+dlm2MCadOgzrkypUrU+5DCJH9SRKxQantL/BfXFzTnr1uMBgA4/LuifHG/Qlseb00IUTWIknEBl0Pvs7RQ8aFJ9etXEf9RvUJvhZM4GXj9rqrlq4y7dWemrA7YXRt3DXN8y/WeNG0b8HBvQd5cOcB/uv8ARg9cDQBGwPS/KwQQjxKkogNKlOuDCuWrKBZ7Wbcv3ef/u/359sfv+XtXm/T1K8pdnZ29Ozb0+zr9/+gPwf2HaD7K93Z+9te8nvkp0P3Dhl4B0KI54WMzrIxXsW92HVkV4rj9RvVx3+vf4rjKzatwC3vvyscfPHNF4QGh7Js5jJ8fXzp90o/ChQuwLfzvqVV61b0bN2T2JhYvEp68d3i77hw7gLbVm9j6ZylvPHuG5l5a2Z7moUqLUWGOguRnCSRbCo4MJjxP45n5KSRDHt7GDs276BJ6yZ07NGRa1ev0bdzXzo07kBBz4I2PzHxaRaqtBQZ6ixEchnyOEsp1UopdV4pdUkp9Wkq55VSakrS+ZNKqRoZUa9IW9FiRSlXuRwAFapUIDQ4lMvnL9O3Q1+G9BmCs70zDRs1ZOGqhRQsVNDK0Qohsqp0t0SUUvbAD0BzIAQ4opRar7U+80ix1kCZpC9fYHrSnyKTPByVBWBnb0dCdAL/N/D/mDx3MmUrlWX9svUcO3DMihEKIbKDjGiJ+ACXtNZXtNaxwFLg5cfKvAws0EYHgTxKqSIZULd4BhHhEeQvlJ+4uDi2rt5q7XCEENlARvSJeADBj7wPIWUrI7UyHsCNDKg/y8qI/QUi70XCY9NKIu9HkpiQaFpCPjYyltioWPq+35eerXtSuEhhXij7ApERkUSERRAbFYu9siciLIL4mHhiwmOICIvA2fH5Wvb91MlT3Lpxi6Ytm1o7FCGyjIxIIqnNjHt8NtvTlDEWVKo/0B+gWLHsPQomo0b5PN7pXKpYKfYe32t6//noz02vB3+Scg/ncd+MM72es3BOhsRkbfHx8Tg4PNuP9+k/T3Py+ElJIkI8g4xIIiGA1yPvPYFQM8oAoLWeCcwE8Pb2lqnVWURmDsNNbZ/5+bPms33zdgoWKUju3LkpV6EcB/YcoFK1Spw6cYo6DevQul1rJo2bxK2btwD4cOiHVKlWhTOnzjB10lSiY6JxdnJm9NjR1KpVi0njJhEdFc3hg4cZMGgAL3d6/KmsEOJxGZFEjgBllFIlgetAN6D7Y2XWAwOUUksxPur6W2v9XD/Kym4ycxju4/vMn/nzDHsO7GGp/1IS4hPo/kp3qvpWxd7VnpjEGOaumQvAZ4M+o9eAXlSvWZ2boTd5v+/7rNqyigo1KjBvzTzsHew5uP8g076bxpIVSxgyYggnj59k3ORxaYUihHhMupOI1jpeKTUA2AbYA3O11qeVUu8knZ8BbAbaAJeASKB3eusVz6/fj/1OoyaNcHY29tk0aPLvPJcWbf9djPLwgcNcuXzF9D4iPIKI8AjCw8MZ/elogq8Gg4LYB7EWi12I7CZDJhtqrTdjTBSPHpvxyGsNvJ8RdQmRem+akYvLv4tRJiYmMn/ZfFOyeWjCmAl4+3oz+YfJhIaE8lbntzIrUiGyPVk7K4t7OMIrs7+cDbYzUqt6zer8tus3YmJiiIyIZO+uvamW86vrx/JFy03vz589D0B4eLhpguWG1RtM53PkyEF4uMxIF+JZyLInWZwtr+P0NPvFQ/J94Tu36czIsSOpVqMavpV92bJ7CwC9X+rNvA3zAKhUtRINGzekW/tuFClahIqVK+KW0y3FdT8Z+Qlff/E1rWu3ximHE7Xq1GLEFyN4o+8bjP50NIvmLTLt2wJQp34dfvj2B5rXbS4d60I8JUkiwqoSEhIY+vnQJ5Z7mEAe6tm3J29/+DbRUdG89fpb9OzTk45dOyYrkydvHr7+7mv6d+rKf1IlAAAb1klEQVTPwFEDqVitIgDValRjrf9aU7lePXsBkNc9L5t3J3sqK4R4AkkiIlOltl98I59GdHu9G7t37KZ3/97sDNhp3BO+Q7s0r1OvdD32XtpLZEQkg3oP4tzpc8REx5C7YG66vtmVXLly0alBJ6r7VOfk0ZOmlYv3/rqXM3+c4fP3P8fJ2Yl5G+bh7GI7j+aEyOokiYg0Pcvcj9TmctwIvcHlq5cZNHoQH372IV/931dMnjyZOOIIjwln8qzJAKzbsI5bd29xOegyUfFRhNwMIUdQDuKI42rIVR5EPiDRIZGg4CDiE+L56MuPyJsnL06OTrz50pv07t+bGyE3Ul25uE2nNiyftzxZS0QIkXEkiYg0Pcvcj8fncgC4RrlSqGQh/JoYd2Fs3709Sxcuxc7Fjnbd2uGWz1jeMYcjTrmdcMvnhr2rPS55XXDL54adix2u7q7EOcehnJXxdXwcCyct5I99f+Bs58ztm7e5e/sukPrKxUKIzCWjs0Smeny/+Ifv/2tf+P+yc/NO7t+7z8Q5E1kSsAT3/O7ExhjneaRYuTg+wcyohRBPS1oi4qlcv3Gd6Li0H20F3wjGJTJ5Yrh16xY3/7rJVv+tVKhYgVWrVlGsbDFOnTlF8I1g/o74G4B/ov/h9r3bBIUEEZ0QzY2/buAW4kYccQTfCCYmLoZEu0QunbvE1cCrYA83r93kxvkb3Ai5QeT9SIBUF52MCIvAyeDE3Rt3ifCKSDX2yHuRhLs93dBeWxrqLIQtkCQinkp0XHSKx1WPcolywTVP8j4Rl2gXvMp5sffAXmbNnIWHlwcdX+/I1m1bccnjgmtuY3lHN0eccjrhmtcVOxc7nPM4m1675HGhcO7CKGdF6fKlKVCkAKM+GcX/xv+P2i/WpnTZ0hQvWhwAg6OBUsVKAZA/b34iHCMoVawUb771Jl9/8TXOLs6sD1ifbEIiQLhrOGVLls3Ib5cQzw1lnExum7y9vfXRo0etHcZz60LgBVOfyOVrl3FzdyM0OJSBbwxk+c7lycoGXQ9KkUQy090rd2lUu1GGXCv8jiQRkX0opY5prb0tVZ/0iQghhDCbPM4SzywhIYExQ8Ykm48xbug4gs4HkTN3TooWK8rQSUNxdnFm0ieTMDgZCLoUxP079+k/vD++TXzxX+XP/u37iYuN42bITRq/1JjXP3idns16Ur95ffoP6w/A/G/nkydfHjr06mDluxZCpEZaIuKZBQcG0/XNrqzYtYKcuXOyY/MOPEt58vJbLzN9w3S8SnmxbcU2U/lb128xcfFEvpz1JVNHTTWNpjp/8jzDJg/jx/U/smfLHi78eQH3wu4c3nEYMC6guHvjbpq0b2KV+xRCPJm0RMQzezgfY/b02Rw9cpSzZ8/iXtCdg/4HWfTtItzc3PBr4sf9e/fZ++te3v30XQI2BrB/535iYmN4s+2bVKtRjXxF8jH83eE4GBzwbujN6aOnMbgYCIsJ491O7xIRHkERzyLkypvL2rcshEiDJBHxzAwGA2dPncV/kz893uxBRHgEC39aSOvXWhN4OZBKFStxO/Q2UQ+i0FoTGxWLSlBcvXiVol5F6f5ed8Z+MpaSJUry9YyvmfvDXC6duUTuXLlJjEukULFCFC9WnKDLQVwPvW4awvuoqL+jTPvTh94KJSYuxuz7cXJ0MvuzluRscLbpBTfF80mSiDDL8aPHady8MQ6ODhgMBhzsHShapCih10I5ffQ0JcuUpFiRYtgpO07sO0HTDk2pUqUKf+z7g+YtmjN59GTuhN4hj2seqlSuwp4Nexgycgh/nPiDN/u/yaTPJhEfH4+dkx3uOd3JmStnsvpdo1yTjajKrF0VbcnDpCmELZEkIsym+Hc2elW/qiz9aSlaaXzr+QIQE2NsHRQvVZz5388n7E4YY6aMwcnZCaUUVWpWYeSHIzn35zk8S3ia1rZyNDjiXdebHLlysHX71mT1CCFsiyQR8UyKehVl+c7lnDt9jtGfjubnFT+TEJ/A5lc202dwHwKvBFKhUgW6dO/C4vmLAahWqxplqpXh7J9nadD8361s87jnYdTkUaxfvZ6zf541Hd+2eRunj53mzY/eZO+BveTIlf1bGUJkVZJEhFnKVypP8zbNee3l1yhStAg1vGsA8EbfNxj20TA2rduUbMOnpxUVEcX2FdtxzuHMnBlzGDV+VEaHLoTIQDJjXaQptRnrtuL2pdu0rN8SSB6npZQpUoaLNy4+02c2rNnApHGTKFCoACs3rUyz3MMdHd3zuSc7LjPrxdOw9Ix1aYkIkcm01mitWbpgKeO/HU/dBnWtHZIQGUaSiMiWfvzuR5ycnOj7bl9GfzqaM6fOsGLjCvbs2sPyRctp2rIpUydPRWtN05ZNGfHlCMDYwuj7bl8Ctgbg7OzMvKXzKFCwANeuXuP9vu+TEJ9Ao2aNktU1/fvpbFi9gdjYWFq1a8WQEUMIDgrm9U6vU6d+HY4dOUartq04fPAw1wZeo0WbFpStUJaTx08ybvI4AN7o8gbvfPgOderXsfS3Soh0SdeMdaWUu1Jqu1LqYtKfedMod1Up9adS6oRSSp5PZRHOBmfC74QTfiecyLBIIu5G2MzXk+Z2+Nbx5dCBQwCc/P0kkeGRxMXFceTAEUqWKsm40eNYvnE5/vv8OXH8BFs3bgUgMiKSGrVqELA/AL+6fqbBAaOGjeKNvm+wefdmChYqaKpn96+7CbwcyKZdm/Df58/JEyc5uO8gAJcvXqbza53x3+vPoOGDqPZiNabNnsbIsSMz469LCKtIb0vkU+BXrfXXSqlPk94PS6NsY631nXTWJyzo8YlttjQX40lzJqq+WJU/T/xJ+D/hGJwMVKlWhT+O/8GhA4do3qo5tevVJl/+fAB07NqRg/sO0qpdKwwGA81bNQegSvUq7Nm5B4AjB48wa9EsADp168S40cYWxO4du9m9Yzct6rUAIDI8ksDLgXh4euBZzJOaPjUz5f6FsBXpTSIvA42SXv8M7CLtJCKExTg6OuJZzJNli5bh7eNNhcoV2L9nP0GBQXh4eXDyxMlUP+fg6GDafdHe3p74+HjTucd3aQRjf8eAQQPo2adnsuPBQcG4uqa9NL6DvQOJiYmm9w/n1AiR1aQ3iRTSWt8A0FrfUEoVTKOcBvyVUhr4SWs9M60LKqX6A/0BihWTJR5sxcNHW7biaXYY9Kvjx4ypM5j8w2QqVKrAF599QdXqValRqwajPx1N2N0wcufJzdqVa+nzdp//vFYtv1qsW7mOTt06sXr5atPxRk0bMXHsRDp27YhbDjduhN7A0dHxibF5Fffi59k/k5iYyI3QG5w4duLJNy2EDXpiElFKBQCFUzk14hnqqau1Dk1KMtuVUue01r+lVjApwcwE4xDfZ6hDZKKsuGaTTx0fpkyagrePN65urjg5OeFTx4dChQsxfPRwurTtgtaaJi2a0LJty/+81pfffMn7fd9nzvQ5tHm5jel4w6YNuXj+Iu2btQfA1c2VqbOmYm9v/5/Xq+VXi2LFi9HUrynlKpajSrUq6b9hIawgXfNElFLngUZJrZAiwC6tdbknfOb/gHCt9aQnXV/miYinYY15ItYg80TE08hqOxuuB3olve4FrHu8gFLKTSmV8+FroAVwKp31CiGEsAHpTSJfA82VUheB5knvUUoVVUptTipTCNirlPoDOAxs0lpvTWe9QgghbEC6Ota11neBpqkcDwXaJL2+AlRLTz1CCCFsk8xYz8KuXb9GdGy0tcPIELLhkhBZkySRLCw6NjrbdCinZ/iwrQ0/zixPM6xZCEuTJCKyPGnBCGE96e1YF0II8RyTJCKEEMJskkSE2R7O0hZCPL8kiQizrQ9Yb+0QhBBWJkkkG+rzWh9aNWhFY5/GLJq3CDButjRu1DhaNWjFq+1f5fejv9O5TWdqV62N/2Z/wLjy7CstX6Fl/Za0rN+SI4eOADBx7ESa121O87rNqVmuJh+/+7HpmgD79+ync5vO9OvZjwY1GzCg7wAeLqfz67ZfaVCzAR1adGDk0JG80eUNS387hBCZSJJINjT5h8ls/W0rm3dvZu6MuYTdDSMyIpLa9Wqz9bet5MiRgwljJrBk3RJmL57NxHETAchfID9L1i1h255tTJ83nVGfjAJg6OdD2b5vO6s2ryKve1569++dos5TJ0/xxddfsOvILoKuBnHk4BGio6MZNnAYi1YtYq3/Wu7euWvR74MQIvPJEN9saO6MuWzZuAWA0OuhBF4OxGAw0Lh5YwDKVyyPwcmAo6MjFSpVIORaCABxcXGMGDKCM3+ewc7ejiuXrpiuqbVmwFsD6Pd+P6q+WDVFndVrVqeoR1EAKlWtZNxPw82V4iWKU6yEcQhuhy4dTC0jIUT2IEkkm9m/Zz97du1hQ8AGXFxd6NymMzExMck2W7Kzs8PJycn0+uHGS7N+mEWBggXYvn87iYmJvFDgBdN1J4+fTBGPIrz6+qup1mswGEyv7e3siU+IN+4iI4TI1iSJZAJLLUcSeiuUsvmTLw3+z4N/yJ0nNy6uLly6cInjR44/9fUePHhAEY8i2NnZseKXFSQkJACwfct2ftv5Gys3r3ym+EqVLUXQ1SCCg4LxKu7F+lXSES9EdiNJJBNYajmSmJCUW6o2ataIhXMW0qx2M14o8wI1atV46uv1eqsX/Xv2Z+OajdRtUBdXN+P2rj9N+4lbN2/RtnFbAFq0bsHQz4c+8XouLi6M/3Y8PTr2wD2fO9VrVn/qWIQQWUO6NqXKbFl1UypLbZL054k/qVLdtnfEiwiPwC2HG1prPhv0GSVLlaT/gP4pysmGS0JkDEtvSiUtEZGpFs9fzIolK4iLjaNy1cr07NPT2iEJITKQDPG1gOCgYJr4NrH4Z21B/wH92b5vO7uO7GLanGm4uLpYOyQhRAaSJCKEEMJs8jjLQuLj4/no7Y84ffI0JUuXZMpPU5gxZQbbt2wnOjoab19vvvn+G5RSnPz9JIPeH4SLiws+tX2sHboQQqRJkoiFXL54mck/TKaWXy0GvTeIn2f/zJv93+TjT41LiHzQ7wO2b91Oi9YtGPTeIMZMHEPterUZ8/mYNK/p5OiUbTZjkg2XhMiaJIlYSFHPotTyqwVAx1c7MnfGXLyKezH9u+lERUVx/959ylUoh18dP/7++29q16sNQKdundi5fWfq1yxUVEY0CSGsSpKIhTycLf7o+88Gfcbm3Zvx8PRg8vjJxETHoLVOUVYIIWyVdKxbyPXg6xw9ZJzzsm7lOmrVNrZK3PO5ExEewaZ1mwDInSc3uXLl4vCBwwCsWb7GOgELIcRTSFcSUUp1UUqdVkolKqXSnNyilGqllDqvlLqklPo0PXVmVWXKlWHFkhU0q92M+/fu06tvL7r36k4zv2b06d6HajWqmcp+++O3fDb4M15q+hLOztJXIISwXemasa6UqgAkAj8BQ7TWKaaXK6XsgQtAcyAEOAK8prU+86Try4z1/yazvIUQj8tSM9a11mch5fP+x/gAl7TWV5LKLgVeBp6YRIQQQtg2S/SJeADBj7wPSTqWKqVUf6XUUaXU0du3b2d6cEIIIcz3xJaIUioAKJzKqRFa63VPUUdqzZQ0n6FprWcCM8H4OOspri+EEMJKnphEtNbN0llHCOD1yHtPIDSd1xRCCGEDLPE46whQRilVUillALoBsjuREEJkA+nqWFdKvQJMBQoAm5RSJ7TWLZVSRYHZWus2Wut4pdQAYBtgD8zVWp9Od+Q2zNngbJHlSGSpECGEtcmmVEIIkY1YeoivzFgXQghhNkkiQgghzCZJRAghhNkkiQghhDCbJBEhhBBmkyQihBDCbJJEhBBCmE2SiBBCCLNJEhFCCGE2SSJCCCHMJklECCGE2SSJCCGEMJskESGEEGaTJCKEEMJskkSEEEKYTZKIEEIIs0kSEUIIYTZJIkIIIcwmSUQIIYTZJIkIIYQwmyQRIYQQZpMkIoQQwmzpSiJKqS5KqdNKqUSllPd/lLuqlPpTKXVCKXU0PXUKIYSwHQ7p/PwpoCPw01OUbay1vpPO+oQQQtiQdCURrfVZAKVUxkQjhBAiS7FUn4gG/JVSx5RS/f+roFKqv1LqqFLq6O3bty0UnhBCCHM8sSWilAoACqdyaoTWet1T1lNXax2qlCoIbFdKndNa/5ZaQa31TGAmgLe3t37K6wshhLCCJyYRrXWz9FaitQ5N+vMvpdQawAdINYkIIYTIOjL9cZZSyk0plfPha6AFxg55IYQQWVy6OtaVUq8AU4ECwCal1AmtdUulVFFgtta6DVAIWJPU+e4A/KK13prOuIXIFq5dv0Z0bLS1w3hqzgZninkUs3YYwoakd3TWGmBNKsdDgTZJr68A1dJTjxDZVXRsNDny57B2GE8t/E64tUMQNkZmrAshhDCbJBEhhBBmkyQihBDCbJJEhBBCmE2SiBBCCLNJEhHChvz43Y/MmT4HgNGfjqZLuy4A7Nm1hw/e+oC1K9bS1K8pTXybMG7UONPnyhQpw7hR42jVoBWvtn+V34/+Tuc2naldtTb+m/0BCA4K5pWWr9Cyfkta1m/JkUNHANi/Zz+d23SmX89+NKjZgAF9B6C1LBYhno4kESFsiG8dXw4dOATAyd9PEhkeSVxcHEcOHKFkqZKMGz2O5RuX47/PnxPHT7B1o3HKVWREJLXr1Wbrb1vJkSMHE8ZMYMm6JcxePJuJ4yYCkL9AfpasW8K2PduYPm86oz4ZZar31MlTfPH1F+w6sougq0EcOXjE8jcvsiRJIkLYkKovVuXPE38S/k84BicDNX1q8sfxPzh04BC5cueidr3a5MufDwcHBzp27cjBfQcBMBgMNG7eGIDyFcvjV88PR0dHKlSqQMi1EADi4uIY+sFQmvo15e1eb3Ph3AVTvdVrVqeoR1Hs7OyoVLUSwUHBlr95kSWldz8RIUQGcnR0xLOYJ8sWLcPbx5sKlSuwf89+ggKD8PDy4OSJk6l+zsHRwbQlg52dHU5OTqbX8fHxAMz6YRYFChZg+/7tJCYm8kKBF0yfNxgMptf2dvbEJ8Rn1i2KbEZaIkLYGL86fsyYOgPfur741vFl4dyFVKpSiRq1anBw30HC7oaRkJDA2pVrqV2v9lNf98GDBxQsXBA7OztWLV1FQkJCJt6FeF5IEhHCxvjU8eGvm3/h7eNNgYIFcHJywqeOD4UKF2L46OF0aduF5nWaU6VaFVq2bfnU1+31Vi9W/rKSdk3aceXSFVzdXDPxLsTzQtnyKAxvb2999KhsyS6yrwuBF7Lc2lllS5a1dhjiPyiljmmtvS1Vn7REhBBCmE2SiBBCCLNJEhFCCGE2SSJCCCHMJvNEhLAiZ4NzltroydngbO0QhI2RJCKEFclWsyKrk8dZQgghzCZJRAghhNkkiQghhDCbJBEhhBBmS1cSUUpNVEqdU0qdVEqtUUrlSaNcK6XUeaXUJaXUp+mpUwghhO1Ib0tkO1BZa10VuAAMf7yAUsoe+AFoDVQEXlNKVUxnvUIIIWxAupKI1tpfa/1w44GDgGcqxXyAS1rrK1rrWGAp8HJ66hVCCGEbMrJPpA+wJZXjHsCj26SFJB1LlVKqv1LqqFLq6O3btzMwPCGEEBntiZMNlVIBQOFUTo3QWq9LKjMCiAcWp3aJVI6luf681nomMBOMS8E/KT4hhBDW88QkorVu9l/nlVK9gHZAU5365iQhgNcj7z2B0GcJUgghhG1K7+isVsAwoL3WOjKNYkeAMkqpkkopA9ANWJ+eeoUQQtiG9PaJTANyAtuVUieUUjMAlFJFlVKbAZI63gcA24CzwHKt9el01iuEEMIGpGsBRq116TSOhwJtHnm/GdicnrqEEELYHpmxLoQQwmySRIQQQphNkogQQgizSRIRQghhNkkiQgghzCZJRAghhNkkiQghhDBbuuaJCJEdXLt+jejYaIvX62xwpphHMYvXK0RGkiQinnvRsdHkyJ/D4vWG3wm3eJ1CZDR5nCWEEMJskkSEEEKYTZKIEEIIs0kSEUIIYTZJIkIIIcwmo7OESEVwUDA9OvbAp7YPx48cp2LlinR9vSuTx0/mzu07TJs9DYDRn44mOjoaZ2dnvp3+LaXLlGbZ4mVs37ydqMgorgZepfVLrfl8zOdWviMhMoe0RIRIw9UrV+n7bl8CDgRw6eIl1q5Yy1r/tYwaN4qpk6dSumxpVm9djf9ef4aMGMI3X3xj+uzpP08zff50fj34K+tXr+d6yHUr3okQmUdaIkKkwau4FxUqVQCgbPmy1GtYD6UU5SuWJ/haMA8ePGDgOwMJvByIUoq4uDjTZ+s1rEeu3LmMny1XluvB1/Hw9LDKfQiRmaQlIkQanJycTK/t7OwwOBlMrxPiE5g4diJ16tdhx6EdzF82n5iYGFN5g8Hw72ft7YiPj7dc4EJYkCQRIcz0z4N/KFy0MADLFy+3cjRCWIfSWls7hjQppW4DQdaOI5PkB+5YOwgrsa17d8IJZxKTHUvAkUhKkpMLAETghSMPMPC36ZwLIURSDEU8DoQTR15ycZYY8pKAK64YO0LCKYkTf+FIBBp3FGEARGNHDDE8H2zr79yyLH3vxbXWBSxVmU0nkexMKXVUa+1t7TiswdbuXZVXZXiNCItU9j+28DGtAViCmz6nL1qkXiuztb9zS8ru9y6Ps4QQQphNkogQQgizSRKxnpnWDsCKnt97z8kia4dgJc/v33k2v3fpExHPPYv2iTzqOeoTEdmXTDYUIpxoluBmlXqFyOKkJSKEEMJs0idiRUqpLkqp00qpRKVUth0C+CilVCul1Hml1CWl1KfWjsdSlFJzlVJ/KaVOWTsWS1JKeSmldiqlzib9rH9k7ZgsRSnlrJQ6rJT6I+nev7B2TJlBkoh1nQI6Ar9ZOxBLUErZAz8ArYGKwGtKqYrWjcpi5gOtrB2EFcQDg7XWFQA/4P3n6O88Bmiita4GVAdaKaX8rBxThpMkYkVa67Na6/PWjsOCfIBLWusrWutYYCnwspVjsgit9W+QNFP9OaK1vqG1Pp70+h/gLPBcrESpjcKT3jomfWW7/gNJIsKSPIDgR96H8Jz8hyJAKVUCeBE4ZN1ILEcpZa+UOgH8BWzXWme7e5fRWZlMKRUAFE7l1Ait9TpLx2NlKpVj2e43M5GSUioHsAoYqLV+YO14LEVrnQBUV0rlAdYopSprrbNVv5gkkUymtW5m7RhsSAjg9ch7TyDUSrEIC1FKOWJMIIu11qutHY81aK3vK6V2YewXy1ZJRB5nCUs6ApRRSpVUShmAbsB6K8ckMpFSSgFzgLNa62+tHY8lKaUKJLVAUEq5AM2Ac9aNKuNJErEipdQrSqkQoDawSSm1zdoxZSatdTwwANiGsYN1udb6tHWjsgyl1BLgAFBOKRWilOpr7ZgspC7QE2iilDqR9NXG2kFZSBFgp1LqJMZfoLZrrTdaOaYMJ5MNhRBCmE1aIkIIIcwmSUQIIYTZJIkIIYQwmyQRIYQQZpMkIoQQwmySRIQQQphNkogQQgiz/T/kl6dJJCYFfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2afbe976e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "visualizeWords = [\n",
    "    \"great\", \"cool\", \"brilliant\", \"wonderful\",  \"amazing\",\n",
    "    \"worth\", \"sweet\", \"boring\", \"bad\", \"dumb\", \"happy\", \n",
    "     \"female\", \"male\", \"queen\", \"king\", \"man\", \"woman\", \"rain\", \"snow\",\n",
    "    \"hail\", \"coffee\", \"tea\"]\n",
    "\n",
    "visualizeIdx = [App2Vec_time.word2index[word] for word in visualizeWords]\n",
    "visualizeVecs = App2Vec_time.wordVectors[visualizeIdx, :]\n",
    "temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
    "covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n",
    "U,S,V = np.linalg.svd(covariance)\n",
    "coord = temp.dot(U[:,0:2])\n",
    "\n",
    "for i in range(len(visualizeWords)):\n",
    "    plt.text(coord[i,0], coord[i,1], visualizeWords[i],\n",
    "        bbox=dict(facecolor='green', alpha=0.1))\n",
    "\n",
    "plt.xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n",
    "plt.ylim((np.min(coord[:,1]), np.max(coord[:,1])))\n",
    "\n",
    "plt.savefig('word_vectors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
